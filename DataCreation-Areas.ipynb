{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_weekday(d, weekday):\n",
    "    days_behind = (d.weekday()-weekday)%7\n",
    "    return d-datetime.timedelta(days_behind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e2bb758aeba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlast_weekday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2019\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "last_weekday(datetime.date(2019,12,10),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing import image, sequence\n",
    "\n",
    "def CreateDataset(start_day, end_day):\n",
    "    years=[]\n",
    "    months=[]\n",
    "    days=[]\n",
    "    area=[]\n",
    "    areadict = {\n",
    "        \"Central Coast\":0,\n",
    "        \"De Anza\":1,\n",
    "        \"Diablo\":2,\n",
    "        \"East Bay\":3,\n",
    "        \"Fresno\":4,\n",
    "        \"Kern\":5,\n",
    "        \"Humboldt\":6,\n",
    "        \"Los Padres\":7,\n",
    "        \"Mission\":8,\n",
    "        \"North Bay\":9,\n",
    "        \"North Valley\":10,\n",
    "        \"Peninsula\":11,\n",
    "        \"Sacramento\":12,\n",
    "        \"San Francisco\":13,\n",
    "        \"San Jose\":14,\n",
    "        \"Sierra\":15,\n",
    "        \"Sonoma\":16,\n",
    "        \"Stockton\":17,\n",
    "        \"Yosemite\":18\n",
    "    }\n",
    "\n",
    "    with open('data-d1p8Q.csv') as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        next(csvReader)\n",
    "        for row in csvReader:\n",
    "            years.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%Y\"))\n",
    "            months.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%m\"))\n",
    "            days.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%d\"))\n",
    "            area.append(row[10])\n",
    "    img_list=[]\n",
    "    date=start_day #datetime.date(2014,1,7)\n",
    "    date_dict = {}\n",
    "    j=0\n",
    "    while date<end_day: #datetime.date(2018,1,3):\n",
    "            img_list.append('C:\\\\Users\\\\alpst\\\\Box Sync\\\\PhD\\\\fire\\\\'+ date.strftime(\"%Y%m%d\")+\".jpg\")\n",
    "            date_dict[date]=j\n",
    "            date=date+datetime.timedelta(days=7)\n",
    "            j=j+1\n",
    "    fire_result=np.zeros((len(img_list),19))\n",
    "\n",
    "    for i in range(len(days)):\n",
    "        d = datetime.date(int(years[i]), int(months[i]), int(days[i]))\n",
    "        last_tuesday=last_weekday(d, 1)# 0 = Monday, 1=Tuesday, 2=Wednesday...\n",
    "        fire_result[date_dict[last_tuesday]][areadict[area[i]]]=1\n",
    "\n",
    "    labels=fire_result\n",
    "   \n",
    "    image_array=[]\n",
    "    sequences_path_array=[]\n",
    "    sequences_labels=[]\n",
    "\n",
    "    for i in range(len(img_list)):\n",
    "\n",
    "        image_array.append(plt.imread(img_list[i]))\n",
    "        \n",
    "       # for j in range(len(image_array)-history_size):\n",
    "            #sequences_path_array.append(img_list[j:j+history_size])\n",
    "            #sequences_labels.append(fire_result[j+history_size]\n",
    "\n",
    "    train_path, test_path, train_y, test_y =  train_test_split(img_list,fire_result, test_size=0.20, random_state=10)\n",
    "    train_path, valid_path, train_y, valid_y = train_test_split(train_path, train_y, test_size=0.20, random_state=10)\n",
    "\n",
    "    return train_path,valid_path, test_path,\\\n",
    "           train_y, valid_y, test_y,\\\n",
    "            image_array, img_list, labels\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing import image, sequence\n",
    "\n",
    "areadict = {\n",
    "    \"Central Coast\":0,\n",
    "    \"De Anza\":1,\n",
    "    \"Diablo\":2,\n",
    "    \"East Bay\":3,\n",
    "    \"Fresno\":4,\n",
    "    \"Kern\":5,\n",
    "    \"Humboldt\":6,\n",
    "    \"Los Padres\":7,\n",
    "    \"Mission\":8,\n",
    "    \"North Bay\":9,\n",
    "    \"North Valley\":10,\n",
    "    \"Peninsula\":11,\n",
    "    \"Sacramento\":12,\n",
    "    \"San Francisco\":13,\n",
    "    \"San Jose\":14,\n",
    "    \"Sierra\":15,\n",
    "    \"Sonoma\":16,\n",
    "    \"Stockton\":17,\n",
    "    \"Yosemite\":18\n",
    "}\n",
    "\n",
    "\n",
    "#def CreateDataset(start_day, end_day):\n",
    "    years=[]\n",
    "    months=[]\n",
    "    days=[]\n",
    "    area=[]\n",
    "    with open('data-d1p8Q.csv') as csvDataFile:\n",
    "        csvReader = csv.reader(csvDataFile)\n",
    "        next(csvReader)\n",
    "        for row in csvReader:\n",
    "            years.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%Y\"))\n",
    "            months.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%m\"))\n",
    "            days.append(datetime.datetime.strptime(row[4],'%m/%d/%Y').strftime(\"%d\"))\n",
    "            area.append(row[1])\n",
    "\n",
    "    img_list=[]\n",
    "    date=start_day #datetime.date(2014,1,7)\n",
    "    positive_maps=[]\n",
    "    fire_result=np.zeros((len(days),18))\n",
    "    j=0\n",
    "    for i in range(len(days)):\n",
    "        d = datetime.date(int(years[i]), int(months[i]), int(days[i]))\n",
    "        next_tuesday=last_weekday(d, 1)# 0 = Monday, 1=Tuesday, 2=Wednesday...\n",
    "        while d<next_tuesday:\n",
    "            positive_maps.append(next_tuesday)\n",
    "            fire_result[j][areadict[area]]=1\n",
    "        j=j+1\n",
    "    while date<end_day: #datetime.date(2018,1,3):\n",
    "        img_list.append('C:\\\\Users\\\\alpst\\\\Box Sync\\\\PhD\\\\fire\\\\'+ date.strftime(\"%Y%m%d\")+\".jpg\")\n",
    "        date=date+datetime.timedelta(days=7)\n",
    "    \n",
    "    labels=fire_result\n",
    "   \n",
    "    image_array=[]\n",
    "    sequences_path_array=[]\n",
    "    sequences_labels=[]\n",
    "\n",
    "    for i in range(len(img_list)):\n",
    "\n",
    "        image_array.append(plt.imread(img_list[i]))\n",
    "        \n",
    "       # for j in range(len(image_array)-history_size):\n",
    "            #sequences_path_array.append(img_list[j:j+history_size])\n",
    "            #sequences_labels.append(fire_result[j+history_size]\n",
    "\n",
    "    train_path, test_path, train_y, test_y =  train_test_split(img_list,fire_result, test_size=0.20, random_state=10)\n",
    "    train_path, valid_path, train_y, valid_y = train_test_split(train_path, train_y, test_size=0.20, random_state=10)\n",
    "\n",
    "    return train_path,valid_path, test_path,\\\n",
    "           train_y, valid_y, test_y,\\\n",
    "            image_array, img_list, labels #, sequence_path_array, sequence_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(images,image_array, figure_shape,to_norm = True):\n",
    "    output_images = []\n",
    "    mean_images=(np.mean(np.array(image_array), axis=tuple(range(np.array(image_array).ndim-1))))\n",
    "    std_images=(np.std(np.array(image_array), axis=tuple(range(np.array(image_array).ndim-1))))\n",
    "    for fig in images:\n",
    "        fig_loaded = image.load_img(fig, target_size=(figure_shape, figure_shape),interpolation='bilinear')\n",
    "        img_arr = image.img_to_array(fig_loaded)\n",
    "        # Scale\n",
    "        figure = (img_arr / 255.).astype(np.float32)\n",
    "        # Normalize\n",
    "        figure = (figure - mean_images) / std_images\n",
    "        output_images.append(figure)\n",
    "    return output_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(X,data_array, y, batch_size):\n",
    "    while True:\n",
    "        indexes = np.arange(len(X))\n",
    "        np.random.shuffle(indexes)\n",
    "        select_indexes = indexes[:batch_size]\n",
    "        data_paths_batch = [X[i] for i in select_indexes]\n",
    "        labels_batch = [y[i] for i in select_indexes]   \n",
    "\n",
    "\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(data_paths,data_array, labels,figure_shape,classes=1):\n",
    "    X, y = [], []\n",
    "    x = image_loader(data_paths, data_array, 128,to_norm=True)\n",
    "    for i in range(len(x)-1):\n",
    "        diff = x[i] - x[i+1] \n",
    "        X.append(diff)\n",
    "        y.append(labels[i+1])\n",
    "    #X = sequence.pad_sequences(X, maxlen=seq_length, padding='pre', truncating='pre')\n",
    "    if classes > 1:\n",
    "        x_ = to_categorical(x_,classes)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sets(X,y,test_size=0.20,random_state=10): \n",
    "    train_X, test_X, train_y, test_y =  train_test_split(X,y, test_size=0.20, random_state=10)\n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, test_size=0.20, random_state=10)\n",
    "\n",
    "    return train_X,valid_X, test_X,\\\n",
    "           train_y, valid_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_path,valid_path, test_path,\\\n",
    "           train_y, valid_y, test_y,\\\n",
    "            image_array, img_list, labels=CreateDataset(datetime.date(2014,1,7), datetime.date(2018,1,3))\n",
    "output_images=image_loader(img_list, image_array, 128,to_norm=True)\n",
    "X,y=get_sequences(img_list, image_array, labels,128,classes=1)\n",
    "train_X,valid_X, test_X,\\\n",
    "           train_y, valid_y, test_y=get_sets(X,y,test_size=0.20,random_state=10)\n",
    "batch_size=2\n",
    "train_gen=data_generator(train_X, image_array,train_y,batch_size)\n",
    "valid_gen=data_generator(valid_X, image_array, valid_y, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object data_generator at 0x000001AE67053308>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_gen)\n",
    "train_y.shape\n",
    "train_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ae00268fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_images=(np.mean(np.array(image_array), axis=tuple(range(np.array(image_array).ndim-1))))\n",
    "std_images=(np.std(np.array(image_array), axis=tuple(range(np.array(image_array).ndim-1))))\n",
    "plt.imshow(X[105]*std_images+mean_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras, math\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, ZeroPadding3D, ConvLSTM2D, Reshape, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from collections import deque\n",
    "import sys\n",
    "import logging\n",
    "from tensorflow.keras.applications import Xception, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "logger = logging.getLogger('Builder_moudle')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "epoch = 30\n",
    "learning_rate = 0.0004\n",
    "batch_size = 32\n",
    "optimizer ='RMSprop'\n",
    "initial_weights = 'Xavier'\n",
    "\n",
    "default_values = dict(epoch=10,\\\n",
    "                      learning_rate=0.0004,\\\n",
    "                      batch_size=16,\\\n",
    "                      optimizer='Adam',\\\n",
    "                      initial_weights=0,\\\n",
    "                      cnn_class=Xception,\\\n",
    "                      pre_weights='Xavier',\\\n",
    "                      dropout=0.5,\\\n",
    "                      lstm_conf=(LSTM,dict(units = 256)),\\\n",
    "                      cnn_train_type='static'\n",
    "                      )\n",
    "\n",
    "\n",
    "def build(epoch = default_values[\"epoch\"],\\\n",
    "          learning_rate = default_values[\"learning_rate\"], \\\n",
    "          batch_size = default_values[\"batch_size\"],\\\n",
    "          optimizer = default_values[\"optimizer\"],\\\n",
    "          initial_weights = default_values[\"initial_weights\"],\\\n",
    "          cnn_class = default_values[\"cnn_class\"],\\\n",
    "          pre_weights = default_values[\"pre_weights\"], \\\n",
    "          dropout=default_values[\"dropout\"], \\\n",
    "          lstm_conf = default_values[\"lstm_conf\"], \\\n",
    "          cnn_train_type=default_values[\"cnn_train_type\"]):\n",
    "\n",
    "    model=0\n",
    "    #Create CNN\n",
    "    if(cnn_train_type!='train'):\n",
    "        logger.info(\"CNN Created with Pre-weights:{}\".format(pre_weights))\n",
    "        base_model = cnn_class(weights=pre_weights,include_top=False)\n",
    "    else:\n",
    "        logger.info(\"CNN Created with no Pre-weights\")\n",
    "        base_model = cnn_class()\n",
    "\n",
    "    #control Train_able of CNNN\n",
    "    if(cnn_train_type=='static'):\n",
    "        logger.info(\"CNN set to NOT-Train\")\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    if(cnn_train_type=='retrain'):\n",
    "        logger.info(\"CNN set to retrain\")\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "    # print(base_model.summary())\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    logger.info(\"base_model.output: {}\".format(base_model.output))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(19, activation='sigmoid')(x)\n",
    "\n",
    "    \n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    print(\"Commit update2\")\n",
    "    print(\"Commit update3\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-0d8ed4145236>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-0d8ed4145236>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    fix_len =\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "figure_size = 128    # split_ratio = 0.1\n",
    "batch_size = 2\n",
    "# batch_epoch_ratio = 0.5 #double the size because we use augmentation\n",
    "fix_len = \n",
    "initial_weights = 'glorot_uniform'\n",
    "weights = 'imagenet'\n",
    "force = True\n",
    "lstm = (ConvLSTM2D, dict(filters=256, kernel_size=(3, 3), padding='same', return_sequences=False))\n",
    "classes = 1\n",
    "\n",
    "# hyper parameters for tunning the network\n",
    "#cnns_arch = dict(ResNet50=ResNet50, InceptionV3=InceptionV3, VGG19=VGG19)  #\n",
    "learning_rates = [1e-4, 1e-3]\n",
    "use_augs = [True, False, ]\n",
    "fix_lens = [20, 10]\n",
    "optimizers = [(RMSprop, {}), (Adam, {})]\n",
    "dropouts = [0.0, 0.5]\n",
    "cnn_train_types = ['retrain', 'static']\n",
    "model = build(size=128, seq_len=None, learning_rate=1e-3,\n",
    "                                   optimizer_class=(Adam, {}), initial_weights=initial_weights,\n",
    "                                   cnn_class=ResNet50, pre_weights=weights, lstm_conf=(ConvLSTM2D, dict(filters=256, kernel_size=(3, 3), padding='same', return_sequences=False)),\n",
    "                                   cnn_train_type='retrain', dropout=0, classes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-08 16:18:45,535 - Builder_moudle - INFO - CNN Created with Pre-weights:imagenet\n",
      "2019-12-08 16:18:45,535 - Builder_moudle - INFO - CNN Created with Pre-weights:imagenet\n",
      "2019-12-08 16:18:48,563 - Builder_moudle - INFO - CNN set to NOT-Train\n",
      "2019-12-08 16:18:48,563 - Builder_moudle - INFO - CNN set to NOT-Train\n",
      "2019-12-08 16:18:48,567 - Builder_moudle - INFO - base_model.output: Tensor(\"block14_sepconv2_act/Identity:0\", shape=(None, None, None, 2048), dtype=float32)\n",
      "2019-12-08 16:18:48,567 - Builder_moudle - INFO - base_model.output: Tensor(\"block14_sepconv2_act/Identity:0\", shape=(None, None, None, 2048), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 19)           19475       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,979,131\n",
      "Trainable params: 2,117,651\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n",
      "Commit update2\n",
      "Commit update3\n"
     ]
    }
   ],
   "source": [
    "model=build(pre_weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, None, 2 0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[1][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 19)           19475       dense[1][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,979,131\n",
      "Trainable params: 2,117,651\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Store the fully connected layers\n",
    "block14=model.layers[-4]\n",
    "global_avg = model.layers[-3]\n",
    "dense_2 = model.layers[-2]\n",
    "predictions = model.layers[-1]\n",
    "\n",
    "dropout1=Dropout (0.5)\n",
    "\n",
    "\n",
    "# Reconnect the layers\n",
    "x = dropout1(block14.output)\n",
    "x=global_avg(x)\n",
    "x = dense_2(x)\n",
    "predictors = predictions(x)\n",
    "\n",
    "# Create a new model\n",
    "model2 = Model(inputs=model.input, outputs=predictors)\n",
    "model2.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=3)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\alpst\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "4/4 [==============================] - 48s 12s/step - loss: 0.6184 - accuracy: 0.6539 - val_loss: 0.6506 - val_accuracy: 0.7508\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 43s 11s/step - loss: 0.5291 - accuracy: 0.7617 - val_loss: 0.6367 - val_accuracy: 0.7570\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 43s 11s/step - loss: 0.4877 - accuracy: 0.7799 - val_loss: 0.6272 - val_accuracy: 0.7291\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 45s 11s/step - loss: 0.4630 - accuracy: 0.7888 - val_loss: 0.6164 - val_accuracy: 0.7632\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 44s 11s/step - loss: 0.4395 - accuracy: 0.8001 - val_loss: 0.6013 - val_accuracy: 0.7632\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 44s 11s/step - loss: 0.4212 - accuracy: 0.8069 - val_loss: 0.5967 - val_accuracy: 0.7632\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 42s 11s/step - loss: 0.3982 - accuracy: 0.8178 - val_loss: 0.5871 - val_accuracy: 0.7632\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 42s 11s/step - loss: 0.3836 - accuracy: 0.8234 - val_loss: 0.5740 - val_accuracy: 0.7632\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 44s 11s/step - loss: 0.3863 - accuracy: 0.8175 - val_loss: 0.5622 - val_accuracy: 0.7601\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 42s 10s/step - loss: 0.3647 - accuracy: 0.8292 - val_loss: 0.5682 - val_accuracy: 0.7632\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.3472 - accuracy: 0.8409 - val_loss: 0.5616 - val_accuracy: 0.7632\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 44s 11s/step - loss: 0.3376 - accuracy: 0.8457 - val_loss: 0.5550 - val_accuracy: 0.7616\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.3365 - accuracy: 0.8456 - val_loss: 0.5317 - val_accuracy: 0.7632\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 42s 11s/step - loss: 0.3630 - accuracy: 0.8262 - val_loss: 0.5517 - val_accuracy: 0.7570\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 44s 11s/step - loss: 0.3181 - accuracy: 0.8530 - val_loss: 0.5477 - val_accuracy: 0.7570\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 41s 10s/step - loss: 0.3128 - accuracy: 0.8563 - val_loss: 0.5446 - val_accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "history=model2.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_X) // batch_size,\n",
    "    epochs=epoch,\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=len(valid_X) // batch_size,\n",
    "    callbacks=[es])\n",
    "\n",
    "model.save_weights('regions_with_dropout_es_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 4s 84ms/sample - loss: 0.5212 - accuracy: 0.7306\n",
      "42/42 [==============================] - 3s 76ms/sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.00      0.00      0.00        12\n",
      "           6       0.00      0.00      0.00        17\n",
      "           7       0.26      1.00      0.42        10\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00        11\n",
      "          10       0.00      0.00      0.00        15\n",
      "          11       0.00      0.00      0.00         6\n",
      "          12       0.00      0.00      0.00        11\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.00      0.00      0.00        19\n",
      "          16       0.00      0.00      0.00         8\n",
      "          17       0.27      0.89      0.41         9\n",
      "          18       0.44      1.00      0.61        17\n",
      "\n",
      "   micro avg       0.33      0.20      0.25       178\n",
      "   macro avg       0.05      0.15      0.08       178\n",
      "weighted avg       0.07      0.20      0.10       178\n",
      " samples avg       0.30      0.16      0.19       178\n",
      "\n",
      "[[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.]]\n",
      "[[False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True False]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False False]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False False False False False False\n",
      "  False False False False False False  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True False]\n",
      " [False False False False False False False  True False False False False\n",
      "  False False False False False  True  True]]\n",
      "[[0.32925072 0.14026925 0.21602881 0.12433162 0.42548797 0.27128813\n",
      "  0.3893498  0.50320226 0.26918977 0.30646116 0.42106444 0.25953406\n",
      "  0.38962236 0.04798365 0.2810803  0.4232375  0.3006481  0.49486107\n",
      "  0.50211865]\n",
      " [0.3286271  0.1409406  0.21946138 0.12361747 0.42327043 0.27301657\n",
      "  0.387717   0.50382036 0.27193552 0.30615842 0.41929704 0.26465598\n",
      "  0.392299   0.04858354 0.27900296 0.42856702 0.3019588  0.5014547\n",
      "  0.50138104]\n",
      " [0.32489377 0.13932738 0.21851984 0.12206841 0.42076978 0.2707289\n",
      "  0.387467   0.50652    0.27124172 0.3056335  0.41914815 0.26508734\n",
      "  0.3917434  0.04835147 0.2776229  0.42699692 0.30355307 0.5014997\n",
      "  0.50047374]\n",
      " [0.3284434  0.14085078 0.21937576 0.12354904 0.42314714 0.27284682\n",
      "  0.38773575 0.50395554 0.27189794 0.30605882 0.41928434 0.26469177\n",
      "  0.39220297 0.04857525 0.2789781  0.42846996 0.3019622  0.50135106\n",
      "  0.50134385]\n",
      " [0.32393965 0.13905442 0.21849325 0.1219784  0.42007807 0.270606\n",
      "  0.38704684 0.5056651  0.27059296 0.30507743 0.4184881  0.2651245\n",
      "  0.3901454  0.04847062 0.27772397 0.42634004 0.30304414 0.50047517\n",
      "  0.49994153]\n",
      " [0.31983256 0.13476378 0.21067542 0.12029162 0.42418    0.261374\n",
      "  0.38871026 0.5179331  0.2723191  0.30830878 0.41606483 0.25980616\n",
      "  0.3906726  0.0467777  0.275392   0.41697028 0.30411375 0.49385485\n",
      "  0.5010623 ]\n",
      " [0.32836902 0.14087847 0.21973813 0.12346864 0.42304292 0.2730227\n",
      "  0.38785902 0.5041433  0.27212715 0.30623704 0.4194623  0.2646507\n",
      "  0.39274687 0.04859221 0.27885443 0.4285081  0.3024903  0.5017697\n",
      "  0.50133276]\n",
      " [0.3291039  0.14172211 0.21694359 0.12599614 0.42844838 0.2726463\n",
      "  0.39032325 0.51424384 0.27022034 0.30802125 0.42122427 0.2660445\n",
      "  0.39238662 0.04790229 0.28121024 0.4262705  0.30356202 0.5016916\n",
      "  0.5094726 ]\n",
      " [0.32968304 0.14180765 0.22352567 0.12409106 0.4193893  0.2710892\n",
      "  0.391051   0.50613236 0.2694665  0.30978733 0.41897547 0.26231253\n",
      "  0.39329728 0.04789954 0.27903017 0.4283483  0.30893356 0.5045983\n",
      "  0.5057111 ]\n",
      " [0.32870904 0.14095977 0.21944743 0.12365776 0.4232851  0.27303916\n",
      "  0.38776708 0.50382113 0.2719068  0.30616468 0.41935152 0.26467323\n",
      "  0.39224565 0.04858464 0.27907085 0.42860097 0.301978   0.5014184\n",
      "  0.50138164]\n",
      " [0.32874027 0.14106855 0.2199491  0.12354788 0.42322984 0.2733427\n",
      "  0.3879142  0.5037478  0.27216393 0.3062799  0.41951758 0.2645784\n",
      "  0.39286426 0.04862091 0.27893525 0.4286732  0.30238914 0.5019117\n",
      "  0.50143534]\n",
      " [0.32922977 0.13954026 0.2181856  0.12366593 0.42549795 0.2712981\n",
      "  0.38844246 0.5003855  0.26821232 0.3061279  0.41792068 0.26103705\n",
      "  0.38806194 0.04812148 0.2810944  0.42639595 0.29899424 0.497069\n",
      "  0.50104415]\n",
      " [0.32999414 0.14296618 0.22718269 0.12510914 0.42564422 0.27156517\n",
      "  0.38718274 0.48934582 0.26397055 0.31042323 0.40666917 0.25436112\n",
      "  0.38459092 0.04809943 0.28008538 0.43165207 0.30089653 0.49392048\n",
      "  0.51183075]\n",
      " [0.32871222 0.1405116  0.21927938 0.12448785 0.42184296 0.2710776\n",
      "  0.38920325 0.50608796 0.27143466 0.30744618 0.4201785  0.26344675\n",
      "  0.39180708 0.0484809  0.27961558 0.42718923 0.30467337 0.49959466\n",
      "  0.50184774]\n",
      " [0.32769102 0.14015913 0.22059172 0.12322336 0.4223036  0.2726559\n",
      "  0.38779762 0.5029881  0.27108556 0.3077995  0.41826183 0.26404607\n",
      "  0.39134374 0.04848856 0.27911258 0.4287532  0.30375123 0.5006942\n",
      "  0.500483  ]\n",
      " [0.32558632 0.13987675 0.21894675 0.12269476 0.42118335 0.2713745\n",
      "  0.38779986 0.50667024 0.27178392 0.30552846 0.41952646 0.26571068\n",
      "  0.39187005 0.04860216 0.2782761  0.42761758 0.30349338 0.50168914\n",
      "  0.50080913]\n",
      " [0.32891777 0.14072204 0.21998256 0.1237528  0.4232654  0.2723817\n",
      "  0.38909173 0.504348   0.2714477  0.3069545  0.41981772 0.26406026\n",
      "  0.39245975 0.04851025 0.2796899  0.4280037  0.30243886 0.5015012\n",
      "  0.5022182 ]\n",
      " [0.32455772 0.13921106 0.21814412 0.12212726 0.4209625  0.27052352\n",
      "  0.38731414 0.50632966 0.27112192 0.30521047 0.4189192  0.26506165\n",
      "  0.39112347 0.04833347 0.27791092 0.42657524 0.30253845 0.5007168\n",
      "  0.50056666]\n",
      " [0.32380366 0.13870856 0.21783167 0.12186149 0.42049825 0.27007082\n",
      "  0.38717908 0.50630957 0.27036935 0.30512142 0.41844505 0.2649833\n",
      "  0.38986683 0.04821393 0.27796257 0.42585906 0.302391   0.49987918\n",
      "  0.5003027 ]\n",
      " [0.3282317  0.14088121 0.21950954 0.12347013 0.42300776 0.27291787\n",
      "  0.38783747 0.50430894 0.2721675  0.30602947 0.4194095  0.2648551\n",
      "  0.3924577  0.048632   0.27894714 0.42841685 0.3022993  0.50164706\n",
      "  0.501321  ]\n",
      " [0.33077753 0.13742161 0.21568763 0.12306502 0.4303156  0.26761645\n",
      "  0.39221394 0.5001128  0.26982188 0.3124863  0.41814625 0.25042927\n",
      "  0.38591915 0.04654005 0.28288186 0.42007014 0.302363   0.4852287\n",
      "  0.503781  ]\n",
      " [0.3283313  0.14080349 0.21973163 0.12376329 0.42206734 0.2725475\n",
      "  0.38761172 0.5027618  0.27166831 0.30717635 0.41880947 0.26376137\n",
      "  0.3924603  0.04858744 0.2787555  0.42735803 0.30223083 0.49975476\n",
      "  0.50055885]\n",
      " [0.328166   0.13974321 0.22009745 0.12368906 0.4215005  0.26949376\n",
      "  0.38775867 0.4916339  0.2668092  0.3041771  0.41724938 0.2551432\n",
      "  0.3857214  0.04820833 0.27962965 0.42686307 0.29916877 0.49131957\n",
      "  0.5022192 ]\n",
      " [0.32600397 0.13981578 0.21887434 0.12288001 0.42170948 0.2714543\n",
      "  0.38809144 0.50659585 0.27176625 0.30578664 0.41950762 0.2655729\n",
      "  0.391562   0.04856035 0.27888602 0.4276113  0.3031231  0.5010574\n",
      "  0.50100577]\n",
      " [0.3286775  0.14107719 0.21976796 0.12357309 0.42331406 0.2732955\n",
      "  0.38783237 0.50372803 0.27214116 0.30611685 0.41939834 0.26469994\n",
      "  0.3925836  0.04863408 0.27903244 0.42867538 0.30209762 0.501771\n",
      "  0.5014674 ]\n",
      " [0.33989856 0.14171055 0.21364677 0.12596947 0.43588763 0.26809156\n",
      "  0.393858   0.50668526 0.27256423 0.31394926 0.4205049  0.25598997\n",
      "  0.38698786 0.04672498 0.28550676 0.423629   0.30200577 0.49518788\n",
      "  0.51136   ]\n",
      " [0.3252002  0.13956869 0.21828482 0.12258172 0.4214464  0.27098215\n",
      "  0.3875078  0.5070327  0.27157104 0.30559498 0.41923764 0.26554996\n",
      "  0.3916166  0.04844314 0.27810854 0.4273225  0.30341992 0.50130135\n",
      "  0.50076944]\n",
      " [0.3256603  0.13999707 0.21883708 0.12284222 0.42137727 0.2715416\n",
      "  0.3876121  0.5066485  0.27172607 0.3053567  0.41924816 0.26584262\n",
      "  0.39169708 0.04866514 0.27829897 0.4277876  0.30351776 0.5017183\n",
      "  0.50070524]\n",
      " [0.32611758 0.13982025 0.21819842 0.12305039 0.42148256 0.27127546\n",
      "  0.3873242  0.505852   0.2714186  0.30507994 0.41889828 0.2654479\n",
      "  0.3907053  0.04856607 0.27867967 0.42761993 0.30237392 0.50014555\n",
      "  0.5003405 ]\n",
      " [0.32889235 0.14106014 0.21963602 0.12366775 0.42343354 0.27321795\n",
      "  0.38786778 0.5037857  0.27200356 0.30628604 0.41943493 0.2646621\n",
      "  0.39246306 0.04859889 0.27910733 0.42870128 0.3020574  0.5016649\n",
      "  0.5015121 ]\n",
      " [0.32462695 0.13941744 0.21850967 0.12238532 0.42010975 0.27079064\n",
      "  0.38730523 0.5055334  0.27064082 0.3053883  0.41882953 0.26510838\n",
      "  0.3902528  0.04847571 0.27797902 0.42642128 0.3030393  0.50038505\n",
      "  0.50011146]\n",
      " [0.32491758 0.13935313 0.21844235 0.12209791 0.42084435 0.27073234\n",
      "  0.3874414  0.5065529  0.2712397  0.3055731  0.4191189  0.26513472\n",
      "  0.39165735 0.04835728 0.2776343  0.42703158 0.30351654 0.50148255\n",
      "  0.50049686]\n",
      " [0.3285664  0.14086196 0.21923122 0.12363738 0.42304182 0.2727688\n",
      "  0.38778237 0.5039721  0.2718128  0.30602956 0.41934153 0.2647707\n",
      "  0.39196262 0.04857096 0.27908796 0.42850918 0.30189323 0.5012325\n",
      "  0.50131834]\n",
      " [0.32855028 0.14091676 0.2194491  0.12357917 0.42321068 0.27295506\n",
      "  0.38774633 0.5039242  0.27196258 0.30612126 0.4193099  0.264696\n",
      "  0.39230454 0.04858571 0.27898008 0.4285401  0.30201226 0.5014738\n",
      "  0.50138766]\n",
      " [0.3260342  0.139938   0.21923727 0.12283793 0.42141545 0.27159894\n",
      "  0.38797975 0.5060393  0.27189654 0.30573213 0.4194045  0.26547366\n",
      "  0.39173815 0.0486362  0.27872556 0.42780432 0.30327815 0.5012101\n",
      "  0.50078404]\n",
      " [0.32760388 0.13826552 0.21832296 0.122316   0.42320183 0.2692418\n",
      "  0.38908425 0.49896547 0.26723444 0.30710047 0.41835207 0.2598076\n",
      "  0.38702294 0.04804087 0.2809161  0.42535555 0.30047745 0.4960643\n",
      "  0.49937385]\n",
      " [0.3282106  0.14075756 0.21940029 0.12346035 0.4228607  0.27272114\n",
      "  0.38779753 0.50417024 0.27191222 0.30601156 0.41934583 0.26478732\n",
      "  0.39219153 0.04859868 0.27895784 0.42839998 0.302163   0.501378\n",
      "  0.5012117 ]\n",
      " [0.32612222 0.13971111 0.21933168 0.12295935 0.42138517 0.2709869\n",
      "  0.38893032 0.50683457 0.27107942 0.30633366 0.42003042 0.2650628\n",
      "  0.39186585 0.04852694 0.27889156 0.42712986 0.3040644  0.50175905\n",
      "  0.50133276]\n",
      " [0.3251714  0.14132354 0.21783918 0.12454879 0.4197734  0.27109605\n",
      "  0.3846831  0.49351472 0.26839137 0.30256516 0.41682467 0.2583817\n",
      "  0.38525146 0.04900086 0.27833122 0.42486262 0.29990405 0.49423456\n",
      "  0.5008981 ]\n",
      " [0.32618824 0.14008924 0.21907157 0.12287417 0.42165327 0.2716819\n",
      "  0.38802984 0.50666445 0.27197656 0.30580586 0.41969395 0.26575285\n",
      "  0.39216244 0.04862282 0.27847683 0.42795932 0.30365306 0.501977\n",
      "  0.5010334 ]\n",
      " [0.3246266  0.13966075 0.21841094 0.12281889 0.42036012 0.27094862\n",
      "  0.38719398 0.5068482  0.27164012 0.30503798 0.41879183 0.2659115\n",
      "  0.3906858  0.04872486 0.27816916 0.42679486 0.30340683 0.50039035\n",
      "  0.49995166]\n",
      " [0.32832038 0.14080232 0.21949035 0.12346345 0.42300302 0.27283412\n",
      "  0.38775188 0.50405866 0.2719399  0.30610082 0.41933453 0.26468843\n",
      "  0.39235502 0.04858691 0.2789347  0.42844224 0.3021084  0.5014649\n",
      "  0.50127417]]\n"
     ]
    }
   ],
   "source": [
    "model2.evaluate(x=test_X, y=test_y)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred = model2.predict(test_X, batch_size=12, verbose=1)\n",
    "predicted = (pred>0.5)\n",
    "report = classification_report(test_y, predicted)\n",
    "print(report)\n",
    "print(test_y)\n",
    "print(predicted)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pred)\n",
    "df.to_csv('prediction_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "        self.test_loss = []\n",
    "        self.test_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x, y = self.test_data\n",
    "        loss, acc = self.model.evaluate(x, y, batch_size=2, verbose=0)\n",
    "        self.test_loss.append(loss)\n",
    "        self.test_acc.append(acc)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_13 to have 5 dimensions, but got array with shape (132, 128, 128, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-c0bc00463f50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    894\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m    895\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2426\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2427\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2428\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    510\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    513\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_13 to have 5 dimensions, but got array with shape (132, 128, 128, 3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "test_history = TestCallback((test_X, test_y))\n",
    "patience_es=15\n",
    "patience_lr=5\n",
    "batch_size=2\n",
    "generator=train_gen\n",
    "validation_data=valid_gen\n",
    "history = model.fit_generator(\n",
    "    generator,\n",
    "    steps_per_epoch=18,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=None,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=len(valid_X)//batch_size,\n",
    "    validation_freq=1,\n",
    "    class_weight=None,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0\n",
    ")\n",
    "                       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
